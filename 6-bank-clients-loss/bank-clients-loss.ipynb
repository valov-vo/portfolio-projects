{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Импорт-библиотек-и-знакомство-с-данными\" data-toc-modified-id=\"Импорт-библиотек-и-знакомство-с-данными-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Импорт библиотек и знакомство с данными</a></span></li><li><span><a href=\"#Предобработка-данных\" data-toc-modified-id=\"Предобработка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Предобработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Итоги-предобработки\" data-toc-modified-id=\"Итоги-предобработки-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Итоги предобработки</a></span></li></ul></li><li><span><a href=\"#Подготовка-данных-и-исследование-задачи\" data-toc-modified-id=\"Подготовка-данных-и-исследование-задачи-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Подготовка данных и исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Дисбаланс\" data-toc-modified-id=\"Дисбаланс-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Дисбаланс</a></span></li><li><span><a href=\"#Подготовка-выборок\" data-toc-modified-id=\"Подготовка-выборок-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Подготовка выборок</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Итоги-исследования-и-обучения-разных-моделей\" data-toc-modified-id=\"Итоги-исследования-и-обучения-разных-моделей-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Итоги исследования и обучения разных моделей</a></span></li></ul></li><li><span><a href=\"#Масштабирование-признаков-и-борьба-с-дисбалансом\" data-toc-modified-id=\"Масштабирование-признаков-и-борьба-с-дисбалансом-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Масштабирование признаков и борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Взвешивание классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Случайный лес</a></span></li><li><span><a href=\"#Решающее-дерево\" data-toc-modified-id=\"Решающее-дерево-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Решающее дерево</a></span></li><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li></ul></li><li><span><a href=\"#Уменьшение-выборки\" data-toc-modified-id=\"Уменьшение-выборки-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Уменьшение выборки</a></span></li><li><span><a href=\"#Итоги-масштабирования-и-борьбы-с-дисбалансом\" data-toc-modified-id=\"Итоги-масштабирования-и-борьбы-с-дисбалансом-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Итоги масштабирования и борьбы с дисбалансом</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Общий-вывод\" data-toc-modified-id=\"Общий-вывод-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Общий вывод</a></span></li><li><span><a href=\"#Чек-лист-готовности-проекта\" data-toc-modified-id=\"Чек-лист-готовности-проекта-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Чек-лист готовности проекта</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Нам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Построим модель с предельно большим значением *F1*-меры (выше или равно 0.59).\n",
    "\n",
    "Дополнительно измерим *AUC-ROC*, сравнивая её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек и знакомство с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые для работы библиотеки и функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файла и взглянем на основную информацию по датафрейму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    clients = pd.read_csv('/datasets/Churn.csv')\n",
    "except:\n",
    "    clients = pd.read_csv('Churn.csv ')\n",
    "    \n",
    "clients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В глаза бросаются не очень \"питоничные\" названия столбцов. Я бы подправил.\n",
    "\n",
    "А также есть пропуски в столбце `Tenure`. Их около 9%, что вполне значимое количество. Судя по описанию, это количественный признак. Первая мысль - заменить пропуски медианным значением по столбцу.\n",
    "\n",
    "С типами данных проблем не вижу.\n",
    "\n",
    "Взглянем визуально на 10 случайных строк датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2274</td>\n",
       "      <td>15679299</td>\n",
       "      <td>Shen</td>\n",
       "      <td>726</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>7.0</td>\n",
       "      <td>123826.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78970.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290</th>\n",
       "      <td>3291</td>\n",
       "      <td>15748589</td>\n",
       "      <td>Winter</td>\n",
       "      <td>736</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34180.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8559</th>\n",
       "      <td>8560</td>\n",
       "      <td>15570857</td>\n",
       "      <td>Kambinachi</td>\n",
       "      <td>677</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111213.64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147578.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>9418</td>\n",
       "      <td>15656829</td>\n",
       "      <td>Hughes</td>\n",
       "      <td>577</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57975.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>2459</td>\n",
       "      <td>15813303</td>\n",
       "      <td>Rearick</td>\n",
       "      <td>513</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>88</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52952.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6621</th>\n",
       "      <td>6622</td>\n",
       "      <td>15710365</td>\n",
       "      <td>Thomson</td>\n",
       "      <td>646</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104129.24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>181794.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8837</th>\n",
       "      <td>8838</td>\n",
       "      <td>15809736</td>\n",
       "      <td>Steigrad</td>\n",
       "      <td>664</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>177423.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8022</th>\n",
       "      <td>8023</td>\n",
       "      <td>15665180</td>\n",
       "      <td>Vasiliev</td>\n",
       "      <td>616</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136789.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59346.40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8442</th>\n",
       "      <td>8443</td>\n",
       "      <td>15677828</td>\n",
       "      <td>Chalmers</td>\n",
       "      <td>598</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60894.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>15581197</td>\n",
       "      <td>Ricci</td>\n",
       "      <td>762</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>51</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99286.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85578.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId     Surname  CreditScore Geography  Gender  Age  \\\n",
       "2273       2274    15679299        Shen          726     Spain  Female   27   \n",
       "3290       3291    15748589      Winter          736    France  Female   30   \n",
       "8559       8560    15570857  Kambinachi          677   Germany  Female   39   \n",
       "9417       9418    15656829      Hughes          577     Spain  Female   33   \n",
       "2458       2459    15813303     Rearick          513     Spain    Male   88   \n",
       "6621       6622    15710365     Thomson          646    France    Male   50   \n",
       "8837       8838    15809736    Steigrad          664    France    Male   46   \n",
       "8022       8023    15665180    Vasiliev          616    France  Female   31   \n",
       "8442       8443    15677828    Chalmers          598    France  Female   34   \n",
       "435         436    15581197       Ricci          762    France  Female   51   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "2273     7.0  123826.07              1          0               1   \n",
       "3290     9.0       0.00              2          1               0   \n",
       "8559     0.0  111213.64              2          1               1   \n",
       "9417     NaN       0.00              2          1               0   \n",
       "2458    10.0       0.00              2          1               1   \n",
       "6621     0.0  104129.24              2          1               0   \n",
       "8837     2.0       0.00              1          1               1   \n",
       "8022     3.0  136789.14              1          1               0   \n",
       "8442     4.0       0.00              2          0               0   \n",
       "435      3.0   99286.98              1          0               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "2273         78970.58       0  \n",
       "3290         34180.33       0  \n",
       "8559        147578.26       0  \n",
       "9417         57975.80       0  \n",
       "2458         52952.24       0  \n",
       "6621        181794.86       1  \n",
       "8837        177423.02       1  \n",
       "8022         59346.40       1  \n",
       "8442         60894.26       0  \n",
       "435          85578.63       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё выглядит пристойно, столбец `RowNumber` для нас абсолютно бесполезен можно будет его удалить - индексы в датафрейме есть. \n",
    "\n",
    "Также обращает на себя внимание, как раз строка с пропуском в `Tenure`. Пришла мысль о том, что это могут быть новые клиенты со \"стажем\" менее года. Взглянем поближе на пропуски, а также проверим, есть ли объекты с нулём в этом столбце."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>415</td>\n",
       "      <td>15810432</td>\n",
       "      <td>Moseley</td>\n",
       "      <td>795</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>167155.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>7399</td>\n",
       "      <td>15577771</td>\n",
       "      <td>Akabueze</td>\n",
       "      <td>453</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111524.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120373.84</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>4305</td>\n",
       "      <td>15770576</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>555</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128061.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62375.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>271</td>\n",
       "      <td>15787071</td>\n",
       "      <td>Dulhunty</td>\n",
       "      <td>650</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>191599.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>7633</td>\n",
       "      <td>15620570</td>\n",
       "      <td>Sinnett</td>\n",
       "      <td>736</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202443.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72375.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7329</th>\n",
       "      <td>7330</td>\n",
       "      <td>15648876</td>\n",
       "      <td>Sandover</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27380.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6608</th>\n",
       "      <td>6609</td>\n",
       "      <td>15576000</td>\n",
       "      <td>Chibueze</td>\n",
       "      <td>765</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138033.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67972.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>690</td>\n",
       "      <td>15720649</td>\n",
       "      <td>Ferdinand</td>\n",
       "      <td>641</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66392.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31106.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2430</th>\n",
       "      <td>2431</td>\n",
       "      <td>15689351</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>742</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92805.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73743.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>3097</td>\n",
       "      <td>15745083</td>\n",
       "      <td>Lei</td>\n",
       "      <td>613</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91415.76</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27965.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "414         415    15810432    Moseley          795     Spain    Male   35   \n",
       "7398       7399    15577771   Akabueze          453   Germany  Female   40   \n",
       "4304       4305    15770576    Hammond          555     Spain    Male   50   \n",
       "270         271    15787071   Dulhunty          650     Spain    Male   41   \n",
       "7632       7633    15620570    Sinnett          736    France    Male   43   \n",
       "7329       7330    15648876   Sandover          501    France  Female   34   \n",
       "6608       6609    15576000   Chibueze          765    France    Male   40   \n",
       "689         690    15720649  Ferdinand          641    France  Female   36   \n",
       "2430       2431    15689351    Johnson          742   Germany  Female   41   \n",
       "3096       3097    15745083        Lei          613   Germany    Male   59   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "414      NaN       0.00              2          1               0   \n",
       "7398     NaN  111524.49              1          1               1   \n",
       "4304     NaN  128061.00              2          1               1   \n",
       "270      NaN       0.00              2          0               1   \n",
       "7632     NaN  202443.47              1          1               0   \n",
       "7329     NaN       0.00              1          1               0   \n",
       "6608     NaN  138033.55              1          1               1   \n",
       "689      NaN   66392.64              1          1               0   \n",
       "2430     NaN   92805.72              1          0               1   \n",
       "3096     NaN   91415.76              1          0               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "414         167155.36       0  \n",
       "7398        120373.84       1  \n",
       "4304         62375.10       0  \n",
       "270         191599.67       0  \n",
       "7632         72375.03       0  \n",
       "7329         27380.99       0  \n",
       "6608         67972.45       0  \n",
       "689          31106.67       0  \n",
       "2430         73743.95       1  \n",
       "3096         27965.00       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients[clients['Tenure'].isna() == True].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По десяти случайным строкам особых закономерностей не видно. Проверим, есть ли нули в этом столбце:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['Tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нули есть и их значимое количество. Значит пропуск не связан со \"стажем\", менее года. Пропуски заменим медианным значением."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнём с названий столбцов: приведем к нижнему регистру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rownumber', 'customerid', 'surname', 'creditscore', 'geography',\n",
      "       'gender', 'age', 'tenure', 'balance', 'numofproducts', 'hascrcard',\n",
      "       'isactivemember', 'estimatedsalary', 'exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for column in clients.columns:\n",
    "    clients = clients.rename(columns={column : column.lower()})\n",
    "\n",
    "print(clients.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Порядок. Теперь добавим нижние подчеркивания для лучшей читаемости названий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_number', 'customer_id', 'surname', 'credit_score', 'geography',\n",
      "       'gender', 'age', 'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
      "       'is_active_member', 'estimated_salary', 'exited'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "clients = clients.rename(columns={\n",
    "    'rownumber' : 'row_number',\n",
    "    'customerid' : 'customer_id',\n",
    "    'creditscore' : 'credit_score',\n",
    "    'numofproducts' : 'num_of_products',\n",
    "    'hascrcard' : 'has_cr_card',\n",
    "    'isactivemember' : 'is_active_member',\n",
    "    'estimatedsalary' : 'estimated_salary'\n",
    "})\n",
    "\n",
    "print(clients.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Питон доволен. Переходим к заполнению пропущенных значений в `tenure` медианным значением по столбцу (медиана меньше подвержена выбросам):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   row_number        10000 non-null  int64  \n",
      " 1   customer_id       10000 non-null  int64  \n",
      " 2   surname           10000 non-null  object \n",
      " 3   credit_score      10000 non-null  int64  \n",
      " 4   geography         10000 non-null  object \n",
      " 5   gender            10000 non-null  object \n",
      " 6   age               10000 non-null  int64  \n",
      " 7   tenure            10000 non-null  float64\n",
      " 8   balance           10000 non-null  float64\n",
      " 9   num_of_products   10000 non-null  int64  \n",
      " 10  has_cr_card       10000 non-null  int64  \n",
      " 11  is_active_member  10000 non-null  int64  \n",
      " 12  estimated_salary  10000 non-null  float64\n",
      " 13  exited            10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tenure_median = clients['tenure'].median()\n",
    "\n",
    "clients['tenure'] = clients['tenure'].fillna(tenure_median)\n",
    "\n",
    "clients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по общей информации, пропусков больше нет, но в довесок хотелось бы взглянуть на случайные строки обновленного датафрейма:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_number</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>geography</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>3040</td>\n",
       "      <td>15666141</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>829</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>101440.36</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19324.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>947</td>\n",
       "      <td>15745324</td>\n",
       "      <td>Milani</td>\n",
       "      <td>599</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>194273.20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3950</th>\n",
       "      <td>3951</td>\n",
       "      <td>15602841</td>\n",
       "      <td>Lockett</td>\n",
       "      <td>794</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>86699.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>7853</td>\n",
       "      <td>15596379</td>\n",
       "      <td>Wallace</td>\n",
       "      <td>743</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>119695.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26136.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>5623</td>\n",
       "      <td>15766649</td>\n",
       "      <td>Vincent</td>\n",
       "      <td>670</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>10.0</td>\n",
       "      <td>89416.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144275.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>1569</td>\n",
       "      <td>15618314</td>\n",
       "      <td>Chu</td>\n",
       "      <td>676</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>114005.78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67998.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2009</td>\n",
       "      <td>15666916</td>\n",
       "      <td>Lira</td>\n",
       "      <td>639</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>99610.92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>187296.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>5919</td>\n",
       "      <td>15742609</td>\n",
       "      <td>Lombardo</td>\n",
       "      <td>600</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>116623.31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59905.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>4105</td>\n",
       "      <td>15676571</td>\n",
       "      <td>Bezrukova</td>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>944.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>6837</td>\n",
       "      <td>15591344</td>\n",
       "      <td>Donnelly</td>\n",
       "      <td>715</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128745.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_number  customer_id    surname  credit_score geography  gender  age  \\\n",
       "3039        3040     15666141    Baldwin           829     Spain  Female   26   \n",
       "946          947     15745324     Milani           599     Spain  Female   39   \n",
       "3950        3951     15602841    Lockett           794     Spain  Female   28   \n",
       "7852        7853     15596379    Wallace           743   Germany    Male   39   \n",
       "5622        5623     15766649    Vincent           670    France    Male   38   \n",
       "1568        1569     15618314        Chu           676    France    Male   40   \n",
       "2008        2009     15666916       Lira           639    France    Male   43   \n",
       "5918        5919     15742609   Lombardo           600   Germany    Male   28   \n",
       "4104        4105     15676571  Bezrukova           850    France    Male   55   \n",
       "6836        6837     15591344   Donnelly           715     Spain    Male   42   \n",
       "\n",
       "      tenure    balance  num_of_products  has_cr_card  is_active_member  \\\n",
       "3039     8.0  101440.36                2            1                 1   \n",
       "946      4.0       0.00                1            1                 0   \n",
       "3950     5.0       0.00                2            0                 1   \n",
       "7852     3.0  119695.75                1            0                 1   \n",
       "5622    10.0   89416.99                1            0                 0   \n",
       "1568     8.0  114005.78                1            1                 1   \n",
       "2008     6.0   99610.92                2            1                 0   \n",
       "5918     2.0  116623.31                1            0                 1   \n",
       "4104     6.0       0.00                1            1                 0   \n",
       "6836     6.0       0.00                2            1                 1   \n",
       "\n",
       "      estimated_salary  exited  \n",
       "3039          19324.50       0  \n",
       "946          194273.20       1  \n",
       "3950          86699.98       0  \n",
       "7852          26136.13       0  \n",
       "5622         144275.39       0  \n",
       "1568          67998.45       0  \n",
       "2008         187296.78       0  \n",
       "5918          59905.29       0  \n",
       "4104            944.41       1  \n",
       "6836         128745.69       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clients.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ах да, хотел удалить ненужный столбец `row_number`. Сделаем это и перейдём к исследованию задачи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'surname', 'credit_score', 'geography', 'gender', 'age',\n",
       "       'tenure', 'balance', 'num_of_products', 'has_cr_card',\n",
       "       'is_active_member', 'estimated_salary', 'exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = clients.drop('row_number', axis=1)\n",
    "\n",
    "clients.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги предобработки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки были приведены к нижнему регистру названия столбцов, добавлены нижние подчёркивания для лучшей читаемости, а также заменены пропуске в столбце `tenure` медианным значением по столбцу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных и исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами стоит задача бинарной классификации, поэтому будем обучать модели решающего дерева, случайного леса и логистической регрессии. Целевой признак находится в столбце `exited`, но прежде чем первый раз обучать модель необходимо провести прямое кодирование признаков в столбцах `geography` и `gender`. Причём можно избавиться от одного из образовавшихся столбцов после кодирования обоих признаков, т.к. по значениям оставшихся мы однозначно определяем и страну, и пол, а лишние признаки негативно сказываются на итогах обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>surname</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>15794187</td>\n",
       "      <td>Young</td>\n",
       "      <td>695</td>\n",
       "      <td>36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>114007.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118120.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>15687079</td>\n",
       "      <td>King</td>\n",
       "      <td>646</td>\n",
       "      <td>69</td>\n",
       "      <td>10.0</td>\n",
       "      <td>115462.44</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40421.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>15768163</td>\n",
       "      <td>Griffin</td>\n",
       "      <td>655</td>\n",
       "      <td>46</td>\n",
       "      <td>7.0</td>\n",
       "      <td>137145.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115146.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id  surname  credit_score  age  tenure    balance  \\\n",
       "5298     15794187    Young           695   36     6.0  114007.50   \n",
       "4313     15687079     King           646   69    10.0  115462.44   \n",
       "9982     15768163  Griffin           655   46     7.0  137145.12   \n",
       "\n",
       "      num_of_products  has_cr_card  is_active_member  estimated_salary  \\\n",
       "5298                2            1                 0         118120.88   \n",
       "4313                1            1                 0          40421.87   \n",
       "9982                1            1                 0         115146.40   \n",
       "\n",
       "      exited  geography_Germany  geography_Spain  gender_Male  \n",
       "5298       0                  0                0            1  \n",
       "4313       0                  0                1            1  \n",
       "9982       1                  1                0            0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = pd.get_dummies(clients, columns=['geography', 'gender'], drop_first=True)\n",
    "\n",
    "clients.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кодирование произведено успешно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дисбаланс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько дисбалансен целевой признак - посчитаем количество единиц в столбце `exited` с целевым признаком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2037"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients['exited'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из десяти тысяч объектов всего чуть больше 20% имеет единичку. Дисбаланс налицо. Обучим модели без учёта дисбаланса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка выборок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим три выборки (обучающую, валидационную и тестовую) в соотношении 60% : 20% : 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(2000, 11)\n",
      "(2000, 11)\n",
      "(6000,)\n",
      "(2000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# создаём датафреймы со свойствами и целевым признаком\n",
    "features = clients.drop(['customer_id', 'surname', 'exited'], axis=1)\n",
    "target = clients['exited']\n",
    "\n",
    "# разделим данные сначала в соотношении 60% на 40%\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "# разделим 40% пополам и получим две части по 20%\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size=0.5, random_state=12345)\n",
    "\n",
    "# проверим размеры получившихся выборок\n",
    "for data in [features_train, features_valid, features_test, target_train, target_valid, target_test]:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ровненько в целевых пропорциях. Приступаем к обучению разних моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель дерева решений:\n",
      "- Глубина: 6\n",
      "- Точность: 77.69%\n",
      "- Полнота: 44.98%\n",
      "- f1-мера: 0.57\n",
      "- AUC-ROC: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_dis_tree_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_dis_tree_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_dis_tree_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_dis_tree_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_dis_tree_depth = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_dis_tree_roc = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10\n",
    "for depth in range(1, 11):\n",
    "    model_dis_tree = DecisionTreeClassifier(max_depth=depth, random_state=12345) # создаём дерево\n",
    "    model_dis_tree.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "    prediction_dis_tree_valid = model_dis_tree.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "    dis_tree_probabilities_one_valid = model_dis_tree.predict_proba(features_valid)[:,1] # определяем вероятности единичек\n",
    "    f1_dis_tree_valid = f1_score(target_valid, prediction_dis_tree_valid) # считаем f1-меру\n",
    "    precision_dis_tree_valid = precision_score(target_valid, prediction_dis_tree_valid)\n",
    "    recall_dis_tree_valid = recall_score(target_valid, prediction_dis_tree_valid)    \n",
    "    roc_tree_valid = roc_auc_score(target_valid, dis_tree_probabilities_one_valid)\n",
    "    # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "    if f1_dis_tree_valid > best_dis_tree_f1:\n",
    "        best_dis_tree_model = model_dis_tree\n",
    "        best_dis_tree_precision = precision_dis_tree_valid\n",
    "        best_dis_tree_recall = recall_dis_tree_valid\n",
    "        best_dis_tree_f1 = f1_dis_tree_valid\n",
    "        best_dis_tree_depth = depth\n",
    "        best_dis_tree_roc = roc_tree_valid\n",
    "\n",
    "print('Лучшая модель дерева решений:')\n",
    "print(f'- Глубина: {best_dis_tree_depth}')\n",
    "print(f'- Точность: {(best_dis_tree_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: {(best_dis_tree_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: {(best_dis_tree_f1).round(2)}')\n",
    "print(f'- AUC-ROC: {(best_dis_tree_roc).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так себе качество в 0,57 по f1-мере. Хотелось бы лучше. Да и питон выдаёт предупреждение, связанное с дисбалансом - не оказалось предсказанных единиц, насколько понимаю. Решив проблему с дисбалансом, избавимся и от предупреждения. Полнота хромает особенно сильно - менее половины правильно предсказанных единиц.\n",
    "AUC-ROC говорит нам о том, что модель далека от случайной. Что-то пытается предсказывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель случайного леса:\n",
      "- Глубина: 10\n",
      "- Количество деревьев: 10\n",
      "- Точность: 79.84%\n",
      "- Полнота: 46.41%\n",
      "- f1-мера: 0.59\n",
      "- AUC-ROC: 0.85\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_dis_forest_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_dis_forest_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_dis_forest_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_dis_forest_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_dis_forest_depth = 0\n",
    "# создаем переменную для значения количества деревьев, обеспечившего максимальную f1-меру\n",
    "best_dis_forest_est = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_dis_forest_roc = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10 и количеству деревьев от 10 до 100\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model_dis_forest = RandomForestClassifier(n_estimators=est, max_depth=depth, random_state=12345) # создаём случайный лес\n",
    "        model_dis_forest.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "        prediction_dis_forest_valid = model_dis_forest.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "        dis_forest_probabilities_one_valid = model_dis_forest.predict_proba(features_valid)[:,1] # определяем вероятности единичек\n",
    "        f1_dis_forest_valid = f1_score(target_valid, prediction_dis_forest_valid) # считаем f1-меру\n",
    "        precision_dis_forest_valid = precision_score(target_valid, prediction_dis_forest_valid)\n",
    "        recall_dis_forest_valid = recall_score(target_valid, prediction_dis_forest_valid)\n",
    "        roc_forest_valid = roc_auc_score(target_valid, dis_forest_probabilities_one_valid)\n",
    "        # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "        if f1_dis_forest_valid > best_dis_forest_f1:\n",
    "            best_dis_forest_model = model_dis_forest\n",
    "            best_dis_forest_est = est\n",
    "            best_dis_forest_precision = precision_dis_forest_valid\n",
    "            best_dis_forest_recall = recall_dis_forest_valid\n",
    "            best_dis_forest_f1 = f1_dis_forest_valid            \n",
    "            best_dis_forest_depth = depth\n",
    "            best_dis_forest_roc = roc_forest_valid\n",
    "\n",
    "print('Лучшая модель случайного леса:')\n",
    "print(f'- Глубина: {best_dis_forest_depth}')\n",
    "print(f'- Количество деревьев: {best_dis_forest_est}')\n",
    "print(f'- Точность: {(best_dis_forest_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: {(best_dis_forest_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: {(best_dis_forest_f1).round(2)}')\n",
    "print(f'- AUC-ROC: {(best_dis_forest_roc).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова предупреждения, связанные с дисбалансом. Но точность и полнота выдали рост на 2% каждый по сравнению с решающим деревом и f1-мера подросла на 0.02. Ну и AUC-ROC подросла на 0.01. Тем не менее, результаты неудовлетворительные. По-прежнему менее половины предсказанных отказников. Может логистическая регрессия покажет себя лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель дерева решений:\n",
      "- Глубина: 100\n",
      "- Точность: 33.9%\n",
      "- Полнота: 4.78%\n",
      "- f1-мера: 0.08\n",
      "- AUC-ROC: 0.67\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_dis_logistic_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_dis_logistic_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_dis_logistic_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_dis_logistic_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_dis_logistic_iter = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_dis_logistic_roc = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10\n",
    "for ite in range(100, 1001, 100):\n",
    "    model_dis_logistic = LogisticRegression(max_iter = ite, solver='liblinear', random_state=12345) # создаём логистическую регрессию\n",
    "    model_dis_logistic.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "    prediction_dis_logistic_valid = model_dis_logistic.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "    dis_logistic_probabilities_one_valid = model_dis_logistic.predict_proba(features_valid)[:,1]\n",
    "    f1_dis_logistic_valid = f1_score(target_valid, prediction_dis_logistic_valid) # считаем f1-меру\n",
    "    precision_dis_logistic_valid = precision_score(target_valid, prediction_dis_logistic_valid)\n",
    "    recall_dis_logistic_valid = recall_score(target_valid, prediction_dis_logistic_valid)\n",
    "    roc_logistic_valid = roc_auc_score(target_valid, dis_logistic_probabilities_one_valid)\n",
    "    # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "    if f1_dis_logistic_valid > best_dis_logistic_f1:\n",
    "        best_dis_logistic_model = model_dis_logistic\n",
    "        best_dis_logistic_precision = precision_dis_logistic_valid\n",
    "        best_dis_logistic_recall = recall_dis_logistic_valid\n",
    "        best_dis_logistic_f1 = f1_dis_logistic_valid\n",
    "        best_dis_logistic_roc = roc_logistic_valid\n",
    "        best_dis_logistic_iter = ite          \n",
    "\n",
    "print('Лучшая модель дерева решений:')\n",
    "print(f'- Глубина: {best_dis_logistic_iter}')\n",
    "print(f'- Точность: {(best_dis_logistic_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: {(best_dis_logistic_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: {(best_dis_logistic_f1).round(2)}')\n",
    "print(f'- AUC-ROC: {(best_dis_logistic_roc).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия в хлам провалилась. Показатели крайне низкие, а AUC-ROC показывает, что данная модель совсем немного лучше, чем случайная модель. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги исследования и обучения разных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составим сводную таблицу с ключевыми параметрами работы дисбалансных моделей, чтобы сравнить результаты и выбрать лучшую, чтобы впоследствии компенсировать дисбаланс классов, соотношение которых на данный момент составляет 80% на 20% (класс \"0\" и класс \"1\" соответственно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Точность, %</th>\n",
       "      <th>Полнота, %</th>\n",
       "      <th>f1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Дерево решений</td>\n",
       "      <td>77.69</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>79.84</td>\n",
       "      <td>46.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Точность, %  Полнота, %  f1-мера  AUC-ROC\n",
       "0           Дерево решений        77.69       44.98     0.57     0.82\n",
       "1            Случайный лес        79.84       46.41     0.59     0.85\n",
       "2  Логистическая регрессия        33.90        4.78     0.08     0.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dis_conclusion = {'Модель' : ['Дерево решений', 'Случайный лес', 'Логистическая регрессия'],\n",
    "                  'Точность, %' : [(best_dis_tree_precision * 100).round(2), (best_dis_forest_precision * 100).round(2), (best_dis_logistic_precision * 100).round(2)],\n",
    "                  'Полнота, %' : [(best_dis_tree_recall * 100).round(2), (best_dis_forest_recall * 100).round(2), (best_dis_logistic_recall * 100).round(2)],\n",
    "                  'f1-мера' : [best_dis_tree_f1.round(2), best_dis_forest_f1.round(2), best_dis_logistic_f1.round(2)],\n",
    "                  'AUC-ROC' : [best_dis_tree_roc.round(2), best_dis_forest_roc.round(2), best_dis_logistic_roc.round(2)]}\n",
    "\n",
    "dis_conclusion = pd.DataFrame(dis_conclusion)\n",
    "display(dis_conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, явный аутсайдер по всем показателям- логистическая регрессия с результатами прогноза слабо отличимых от случайного выбора.\n",
    "А вот случайный лес и решающее дерево показали себя схожим образом, но примерно на 2% по полноте и точности лес получше. При этом для практического применения модели непригодны - уж больно мала полнота. AUC-ROC очень оптимистична - гораздо больше f1-меры. Что говорит нам о том, что нужно применять эти метрики в связке. Большое значение одной ещё не говорит о безоговорочно высоком качестве модели.\n",
    "\n",
    "Далее будем улучшать данные и балансировать классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Масштабирование признаков и борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем масштабирование количественных признаков в столбцах `balance`, `tenure`, `num_of_products`, `estimated_salary`, `age`, `credit_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/3696609357.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[numeric] = scaler.transform(data[numeric])\n",
      "/opt/conda/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>num_of_products</th>\n",
       "      <th>has_cr_card</th>\n",
       "      <th>is_active_member</th>\n",
       "      <th>estimated_salary</th>\n",
       "      <th>geography_Germany</th>\n",
       "      <th>geography_Spain</th>\n",
       "      <th>gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8047</th>\n",
       "      <td>0.847513</td>\n",
       "      <td>-0.562998</td>\n",
       "      <td>-0.009707</td>\n",
       "      <td>0.729337</td>\n",
       "      <td>-0.891560</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.652362</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>0.047883</td>\n",
       "      <td>-0.183385</td>\n",
       "      <td>-1.101690</td>\n",
       "      <td>-1.233163</td>\n",
       "      <td>0.830152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.590405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>-0.741363</td>\n",
       "      <td>0.386035</td>\n",
       "      <td>-0.009707</td>\n",
       "      <td>0.268265</td>\n",
       "      <td>2.551864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      credit_score       age    tenure   balance  num_of_products  \\\n",
       "8047      0.847513 -0.562998 -0.009707  0.729337        -0.891560   \n",
       "3414      0.047883 -0.183385 -1.101690 -1.233163         0.830152   \n",
       "8101     -0.741363  0.386035 -0.009707  0.268265         2.551864   \n",
       "\n",
       "      has_cr_card  is_active_member  estimated_salary  geography_Germany  \\\n",
       "8047            1                 0         -0.652362                  1   \n",
       "3414            1                 1         -1.590405                  0   \n",
       "8101            1                 0          0.719409                  1   \n",
       "\n",
       "      geography_Spain  gender_Male  \n",
       "8047                0            1  \n",
       "3414                0            0  \n",
       "8101                0            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# создаём список столбцов с количественными переменными\n",
    "numeric = ['balance', 'tenure', 'num_of_products', 'estimated_salary', 'age', 'credit_score']\n",
    "\n",
    "# создаём \"масштабатор\" :-)\n",
    "scaler = StandardScaler()\n",
    "# тренируем \"масштабатор\" на обучающей выборке\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "# циклом преобразуем данные в выборках, которые задействованы в обучении и тестировании модели\n",
    "for data in [features_train, features_valid, features_test]:\n",
    "    data[numeric] = scaler.transform(data[numeric])\n",
    "    \n",
    "# проверим результат визуально\n",
    "display(features_test.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные масштабированы. Переходим к борьбе с дисбалансом. Применим взвешивание классов и уменьшение выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим при обучении моделей случайного леса гиперпараметр class_weight = 'balanced'. Так же с помощью цикла переберем гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес (взвешивание классов):\n",
      "- Глубина: было - 10; стало - 9\n",
      "- Количество деревьев: было - 10; стало - 90\n",
      "- Точность: было - 79.84%; стало - 60.62%\n",
      "- Полнота: было - 46.41%; стало - 65.55%\n",
      "- f1-мера: было - 0.59; стало - 0.63\n",
      "- AUC-ROC: было - 0.85; стало - 0.86\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_forest_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_forest_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_forest_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_forest_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_forest_depth = 0\n",
    "# создаем переменную для значения количества деревьев, обеспечившего максимальную f1-меру\n",
    "best_forest_est = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_forest_roc_bal = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10 и количеству деревьев от 10 до 100\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model_forest = RandomForestClassifier(n_estimators=est, max_depth=depth, class_weight='balanced', random_state=12345) # создаём случайный лес\n",
    "        model_forest.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "        prediction_forest_valid = model_forest.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "        forest_probabilities_one_valid = model_forest.predict_proba(features_valid)[:,1]\n",
    "        f1_forest_valid = f1_score(target_valid, prediction_forest_valid) # считаем f1-меру\n",
    "        precision_forest_valid = precision_score(target_valid, prediction_forest_valid)\n",
    "        recall_forest_valid = recall_score(target_valid, prediction_forest_valid)\n",
    "        roc_forest_valid = roc_auc_score(target_valid, forest_probabilities_one_valid)\n",
    "        # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "        if f1_forest_valid > best_forest_f1:\n",
    "            best_forest_model = model_forest\n",
    "            best_forest_est = est\n",
    "            best_forest_precision = precision_forest_valid\n",
    "            best_forest_recall = recall_forest_valid\n",
    "            best_forest_f1 = f1_forest_valid            \n",
    "            best_forest_depth = depth\n",
    "            best_forest_roc_bal = roc_forest_valid\n",
    "\n",
    "print('Случайный лес (взвешивание классов):')\n",
    "print(f'- Глубина: было - {best_dis_forest_depth}; стало - {best_forest_depth}')\n",
    "print(f'- Количество деревьев: было - {best_dis_forest_est}; стало - {best_forest_est}')\n",
    "print(f'- Точность: было - {(best_dis_forest_precision * 100).round(2)}%; стало - {(best_forest_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: было - {(best_dis_forest_recall * 100).round(2)}%; стало - {(best_forest_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: было - {(best_dis_forest_f1).round(2)}; стало - {(best_forest_f1).round(2)}')\n",
    "print(f'- AUC-ROC: было - {(best_dis_forest_roc).round(2)}; стало - {(best_forest_roc_bal).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и предполагалось. Предупреждения от питона пропали после устранения дисбаланса.\n",
    "\n",
    "Точность, конечно, сильно упала (на 19%), но полнота примерно так-же выросла, что резко повысило качество модели в определении потенциальных клиентов, собирающихся на выход. Что нам собственно и необходимо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель дерева решений:\n",
      "- Глубина: было - 6; стало - 5\n",
      "- Точность: было - 77.69%; стало - 53.74%\n",
      "- Полнота: было - 44.98%; стало - 66.99%\n",
      "- f1-мера: было - 0.57; стало - 0.6\n",
      "- AUC-ROC: было - 0.82; стало - 0.83\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_tree_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_tree_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_tree_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_tree_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_tree_depth = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_tree_roc = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10\n",
    "for depth in range(1, 11):\n",
    "    model_tree = DecisionTreeClassifier(max_depth=depth, class_weight='balanced', random_state=12345) # создаём дерево\n",
    "    model_tree.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "    prediction_tree_valid = model_tree.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "    tree_probabilities_one_valid = model_tree.predict_proba(features_valid)[:,1] # определяем вероятности единичек\n",
    "    f1_tree_valid = f1_score(target_valid, prediction_tree_valid) # считаем f1-меру\n",
    "    precision_tree_valid = precision_score(target_valid, prediction_tree_valid)\n",
    "    recall_tree_valid = recall_score(target_valid, prediction_tree_valid)    \n",
    "    roc_tree_valid = roc_auc_score(target_valid, tree_probabilities_one_valid)\n",
    "    # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "    if f1_tree_valid > best_tree_f1:\n",
    "        best_tree_model = model_tree\n",
    "        best_tree_precision = precision_tree_valid\n",
    "        best_tree_recall = recall_tree_valid\n",
    "        best_tree_f1 = f1_tree_valid\n",
    "        best_tree_depth = depth\n",
    "        best_tree_roc = roc_tree_valid\n",
    "\n",
    "print('Лучшая модель дерева решений:')\n",
    "print(f'- Глубина: было - {best_dis_tree_depth}; стало - {best_tree_depth}')\n",
    "print(f'- Точность: было - {(best_dis_tree_precision * 100).round(2)}%; стало - {(best_tree_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: было - {(best_dis_tree_recall * 100).round(2)}%; стало - {(best_tree_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: было - {(best_dis_tree_f1).round(2)}; стало - {(best_tree_f1).round(2)}')\n",
    "print(f'- AUC-ROC: было - {(best_dis_tree_roc).round(2)}; стало - {(best_tree_roc).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взвешивание дало схожий эффект - резкое падение точности на 24% и резкий взлёт полноты на 22%, что дало рост f1-меры на 0,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель логистической регрессии:\n",
      "- Итераций: было - 100; стало - 100\n",
      "- Точность: было - 33.9%; стало - 38.1%\n",
      "- Полнота: было - 4.78%; стало - 68.18%\n",
      "- f1-мера: было - 0.08; стало - 0.49\n",
      "- AUC-ROC: было - 0.67; стало - 0.76\n"
     ]
    }
   ],
   "source": [
    "# создаем переменную для модели с лучшим показателем f1-меры\n",
    "best_logistic_model = None\n",
    "# создаем переменную для лучшего показателя f1-меры\n",
    "best_logistic_f1 = 0\n",
    "# создаем переменную для точности при лучшем показателе f1-меры\n",
    "best_logistic_precision = 0\n",
    "# создаем переменную для полноты при лучшем показателе f1-меры\n",
    "best_logistic_recall = 0\n",
    "# создаем переменную для значения максимальной глубины, обеспечившей максимальную f1-меру\n",
    "best_logistic_iter = 0\n",
    "# создаем переменную для значения площади под roc-кривой, при максимальной f1-мере\n",
    "best_logistic_roc = 0\n",
    "\n",
    "# пробежимся по значениям глубины от 1 до 10\n",
    "for ite in range(100, 1001, 100):\n",
    "    model_logistic = LogisticRegression(max_iter = ite, solver='liblinear', class_weight='balanced', random_state=12345) # создаём логистическую регрессию\n",
    "    model_logistic.fit(features_train, target_train) # тренируем на тренировочной выборке\n",
    "    prediction_logistic_valid = model_logistic.predict(features_valid) # предсказываем результаты по валидационным свойствам\n",
    "    logistic_probabilities_one_valid = model_logistic.predict_proba(features_valid)[:,1]\n",
    "    f1_logistic_valid = f1_score(target_valid, prediction_logistic_valid) # считаем f1-меру\n",
    "    precision_logistic_valid = precision_score(target_valid, prediction_logistic_valid)\n",
    "    recall_logistic_valid = recall_score(target_valid, prediction_logistic_valid)\n",
    "    roc_logistic_valid = roc_auc_score(target_valid, logistic_probabilities_one_valid)\n",
    "    # условной конструкцией записываем в ранее созданные переменные лучшие показатели\n",
    "    if f1_logistic_valid > best_logistic_f1:\n",
    "        best_logistic_model = model_logistic\n",
    "        best_logistic_precision = precision_logistic_valid\n",
    "        best_logistic_recall = recall_logistic_valid\n",
    "        best_logistic_f1 = f1_logistic_valid\n",
    "        best_logistic_roc = roc_logistic_valid\n",
    "        best_logistic_iter = ite          \n",
    "\n",
    "print('Лучшая модель логистической регрессии:')\n",
    "print(f'- Итераций: было - {best_dis_logistic_iter}; стало - {best_logistic_iter}')\n",
    "print(f'- Точность: было - {(best_dis_logistic_precision * 100).round(2)}%; стало - {(best_logistic_precision * 100).round(2)}%')\n",
    "print(f'- Полнота: было - {(best_dis_logistic_recall * 100).round(2)}%; стало - {(best_logistic_recall * 100).round(2)}%')\n",
    "print(f'- f1-мера: было - {(best_dis_logistic_f1).round(2)}; стало - {(best_logistic_f1).round(2)}')\n",
    "print(f'- AUC-ROC: было - {(best_dis_logistic_roc).round(2)}; стало - {(best_logistic_roc).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия ожила сильнее всех моделей после борьбы с дисбалансом - рост точности на 4%, полноты на 63% (!) и f1-меры на 0,41! Линейная модель действительно максимально чувствительна к балансу классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если учесть, что дисбаланс 80 на 20, при уменьшении выборки нужно оставить 25% нулей, чтобы получить примерное равенство объектов с классом \"0\" и классом \"1\". Обучим модель случайного леса с гиперпараметрами лучшей модели, получившейся после взвешивания классов, чтобы корректно сравнить результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес (уменьшение выборки):\n",
      "- Глубина: 9\n",
      "- Количество деревьев: 90\n",
      "- Точность: 48.91%\n",
      "- Полнота: 74.88%\n",
      "- f1-мера: 0.59\n",
      "- AUC-ROC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# создадим функцию для уменьшения выборки\n",
    "def downsample(features, target, fraction):\n",
    "    # разделим выборки по классам\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    # сформируем сбалансированные выборки из случайно выбранных нулей и всех единиц\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    # перемешаем получившиеся выборки\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "# применим функцию к обучающей выборке, обучим модель и проверим результат на валидационной выборке\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.25)\n",
    "\n",
    "forest_model_down = RandomForestClassifier(n_estimators=best_forest_est, max_depth=best_forest_depth, random_state=12345)\n",
    "forest_model_down.fit(features_downsampled, target_downsampled)\n",
    "forest_down_valid_pred = forest_model_down.predict(features_valid)\n",
    "\n",
    "f1_forest_down_valid = f1_score(target_valid, forest_down_valid_pred)\n",
    "precision_forest_down_valid = precision_score(target_valid, forest_down_valid_pred)\n",
    "recall_forest_down_valid = recall_score(target_valid, forest_down_valid_pred)\n",
    "roc_forest_down_valid = roc_auc_score(target_valid, forest_down_valid_pred)\n",
    "\n",
    "print('Случайный лес (уменьшение выборки):')\n",
    "print(f'- Глубина: {best_forest_depth}')\n",
    "print(f'- Количество деревьев: {best_forest_est}')\n",
    "print(f'- Точность: {(precision_forest_down_valid * 100).round(2)}%')\n",
    "print(f'- Полнота: {(recall_forest_down_valid * 100).round(2)}%')\n",
    "print(f'- f1-мера: {(f1_forest_down_valid).round(2)}')\n",
    "print(f'- AUC-ROC: {(roc_forest_down_valid).round(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итоги масштабирования и борьбы с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поместим результаты обучения моделей случайного леса после масштабирования и борьбы с дисбалансом в одну таблицу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Метод балансирования</th>\n",
       "      <th>Точность, %</th>\n",
       "      <th>Полнота, %</th>\n",
       "      <th>f1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Взвешивание классов</td>\n",
       "      <td>60.62</td>\n",
       "      <td>65.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Уменьшение выборки</td>\n",
       "      <td>48.91</td>\n",
       "      <td>74.88</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Метод балансирования  Точность, %  Полнота, %  f1-мера  AUC-ROC\n",
       "0  Взвешивание классов        60.62       65.55     0.63     0.86\n",
       "1   Уменьшение выборки        48.91       74.88     0.59     0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balance_conclusion = {'Метод балансирования' : ['Взвешивание классов', 'Уменьшение выборки'],\n",
    "                     'Точность, %' : [(best_forest_precision * 100).round(2), (precision_forest_down_valid * 100).round(2)],\n",
    "                     'Полнота, %' : [(best_forest_recall * 100).round(2), (recall_forest_down_valid * 100).round(2)],\n",
    "                     'f1-мера' : [(best_forest_f1).round(2), (f1_forest_down_valid).round(2)],\n",
    "                     'AUC-ROC' : [(best_forest_roc_bal).round(2), (roc_forest_down_valid).round(2)]}\n",
    "\n",
    "balance_conclusion = pd.DataFrame(balance_conclusion)\n",
    "display(balance_conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реальный эффект по качеству модели случайного дало взвешивание классов, а не уменьшение выборки, которая не улучшила f1-меру, а точность и AUC-ROC вообще \"обвалила\", поэтому примем именно модель со взвешенными классами для проверки на тестовой выборке.\n",
    "\n",
    "Также видим, что AUC-ROC сильно выше f1-меры. Данные метрики нужно применять в связке, а не по отдельности.\n",
    "\n",
    "Вцелом после масштабирования и борьбы с дисбалансом мы получили рост качества модели по AUC-ROC на 0.01 и f1-меры на 0.04\n",
    "\n",
    "Также эксперименты показали, что логистическая регрессия намного более чувствительна к дисбалансу классов - после его устранения рост точности на 4%, полноты на 63% (!) и f1-меры на 0,41!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем модель случайного леса со взвешенными классами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сводный отчёт по тесту лучшей модели случайного леса:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      1577\n",
      "           1       0.62      0.59      0.60       423\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.74      0.75      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_forest_test_predict = model_forest.predict(features_test)\n",
    "\n",
    "print('Сводный отчёт по тесту лучшей модели случайного леса:')\n",
    "print(classification_report(target_test, model_forest_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом цель достигнута: показатель f1-меры по результатам теста - 0.60, что больше, чем 0.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе предобработки были приведены к нижнему регистру названия столбцов, добавлены нижние подчёркивания для лучшей читаемости, а также заменены пропуске в столбце `tenure` медианным значением по столбцу.\n",
    "\n",
    "По итогам исследования дисбаланса и обучения \"дисбалансных\" моделей, составили сводную таблицу с ключевыми параметрами работы моделей решающего дерева, случайного леса и логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Точность, %</th>\n",
       "      <th>Полнота, %</th>\n",
       "      <th>f1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Дерево решений</td>\n",
       "      <td>77.69</td>\n",
       "      <td>44.98</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>79.84</td>\n",
       "      <td>46.41</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>33.90</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  Точность, %  Полнота, %  f1-мера  AUC-ROC\n",
       "0           Дерево решений        77.69       44.98     0.57     0.82\n",
       "1            Случайный лес        79.84       46.41     0.59     0.85\n",
       "2  Логистическая регрессия        33.90        4.78     0.08     0.67"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dis_conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cравнили результаты и выбрали для дальнейшей работы случайный лес, т.к. эта модель показала лучшие результаты по всем ключевым метрикам. Предстояло масштабировать количественные признаки и компенсировать дисбаланс классов, соотношение которых составляло 80% на 20% (класс \"0\" и класс \"1\" соответственно).\n",
    "\n",
    "Масштабировали признаки в столбцах `balance`, `tenure`, `num_of_products`, `estimated_salary`, `age`, `credit_score`, а затем последовательно компенсировали дисбаланс взвешиванием классов и уменьшением выборки, получив следующие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Метод балансирования</th>\n",
       "      <th>Точность, %</th>\n",
       "      <th>Полнота, %</th>\n",
       "      <th>f1-мера</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Взвешивание классов</td>\n",
       "      <td>60.62</td>\n",
       "      <td>65.55</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Уменьшение выборки</td>\n",
       "      <td>48.91</td>\n",
       "      <td>74.88</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Метод балансирования  Точность, %  Полнота, %  f1-мера  AUC-ROC\n",
       "0  Взвешивание классов        60.62       65.55     0.63     0.86\n",
       "1   Уменьшение выборки        48.91       74.88     0.59     0.77"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(balance_conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реальный эффект по качеству модели случайного леса дало взвешивание классов, а не уменьшение выборки, которая не улучшила f1-меру, а точность и AUC-ROC вообще \"обвалила\", поэтому примем именно модель со взвешенными классами для проверки на тестовой выборке.\n",
    "\n",
    "**Вцелом после масштабирования и борьбы с дисбалансом мы получили рост качества модели по AUC-ROC на 0.01 и f1-меры на 0.04**\n",
    "\n",
    "Также эксперименты показали, что логистическая регрессия намного более чувствительна к дисбалансу классов - после его устранения рост точности на 4%, полноты на 63% (!) и f1-меры на 0,41!\n",
    "\n",
    "По итогам теста выбранной модели (переменная `model_forest`) получили следующие результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      1577\n",
      "           1       0.62      0.59      0.60       423\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.74      0.75      2000\n",
      "weighted avg       0.83      0.83      0.83      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(target_test, model_forest_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивая по ходу работы AUC-ROC и f1-меру сделали вывод, что эти метрики нужно применять в связке. Высокое значение одной ещё не означает, что жизнь удалась. Нужно смотреть другие тоже.\n",
    "\n",
    "**Цель достигнута: показатель f1-меры по результатам теста - 0.60**\n",
    "\n",
    "Это означает, что применяя данную модель можно выявить и попытаться удержать более 60% клиентов, которые собираются уходить."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 1133,
    "start_time": "2022-07-18T07:37:17.835Z"
   },
   {
    "duration": 182,
    "start_time": "2022-07-18T07:37:18.971Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.157Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.158Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.159Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.160Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.161Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.162Z"
   },
   {
    "duration": 1,
    "start_time": "2022-07-18T07:37:19.162Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.164Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.165Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.166Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.167Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.169Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.170Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.171Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.172Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.173Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.174Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.175Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.176Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.177Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.178Z"
   },
   {
    "duration": 0,
    "start_time": "2022-07-18T07:37:19.179Z"
   },
   {
    "duration": 1224,
    "start_time": "2022-07-18T07:53:59.135Z"
   },
   {
    "duration": 55,
    "start_time": "2022-07-18T07:54:00.361Z"
   },
   {
    "duration": 22,
    "start_time": "2022-07-18T07:54:00.418Z"
   },
   {
    "duration": 29,
    "start_time": "2022-07-18T07:54:00.441Z"
   },
   {
    "duration": 21,
    "start_time": "2022-07-18T07:54:00.472Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T07:54:00.494Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-18T07:54:00.510Z"
   },
   {
    "duration": 18,
    "start_time": "2022-07-18T07:54:00.515Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-18T07:54:00.534Z"
   },
   {
    "duration": 34,
    "start_time": "2022-07-18T07:54:00.553Z"
   },
   {
    "duration": 76,
    "start_time": "2022-07-18T07:54:00.588Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-18T07:54:00.666Z"
   },
   {
    "duration": 26,
    "start_time": "2022-07-18T07:54:00.681Z"
   },
   {
    "duration": 216,
    "start_time": "2022-07-18T07:54:00.709Z"
   },
   {
    "duration": 22140,
    "start_time": "2022-07-18T07:54:00.927Z"
   },
   {
    "duration": 1598,
    "start_time": "2022-07-18T07:54:23.068Z"
   },
   {
    "duration": 179,
    "start_time": "2022-07-18T07:54:24.669Z"
   },
   {
    "duration": 46,
    "start_time": "2022-07-18T07:54:24.850Z"
   },
   {
    "duration": 22397,
    "start_time": "2022-07-18T07:54:24.898Z"
   },
   {
    "duration": 299,
    "start_time": "2022-07-18T07:54:47.296Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-18T07:54:47.596Z"
   },
   {
    "duration": 63,
    "start_time": "2022-07-18T07:54:47.607Z"
   },
   {
    "duration": 9,
    "start_time": "2022-07-18T07:54:47.672Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-18T07:54:47.682Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-18T07:54:47.695Z"
   },
   {
    "duration": 1095,
    "start_time": "2022-07-18T09:16:23.590Z"
   },
   {
    "duration": 87,
    "start_time": "2022-07-18T09:16:24.687Z"
   },
   {
    "duration": 25,
    "start_time": "2022-07-18T09:16:24.775Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-18T09:16:24.801Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-18T09:16:24.820Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T09:16:24.827Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-18T09:16:24.843Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-18T09:16:24.848Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T09:16:24.867Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-18T09:16:24.883Z"
   },
   {
    "duration": 62,
    "start_time": "2022-07-18T09:16:24.892Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-18T09:16:24.957Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-18T09:16:24.964Z"
   },
   {
    "duration": 225,
    "start_time": "2022-07-18T09:16:24.986Z"
   },
   {
    "duration": 23757,
    "start_time": "2022-07-18T09:18:02.120Z"
   },
   {
    "duration": 1873,
    "start_time": "2022-07-18T09:19:43.850Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-18T09:20:00.319Z"
   },
   {
    "duration": 3,
    "start_time": "2022-07-18T09:24:27.440Z"
   },
   {
    "duration": 50,
    "start_time": "2022-07-18T09:24:27.445Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T09:24:27.497Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-18T09:24:27.513Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-18T09:24:27.531Z"
   },
   {
    "duration": 15,
    "start_time": "2022-07-18T09:24:27.538Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-18T09:24:27.554Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-18T09:24:27.560Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T09:24:27.577Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-18T09:24:27.594Z"
   },
   {
    "duration": 20,
    "start_time": "2022-07-18T09:24:27.623Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-18T09:24:27.644Z"
   },
   {
    "duration": 14,
    "start_time": "2022-07-18T09:24:27.649Z"
   },
   {
    "duration": 234,
    "start_time": "2022-07-18T09:24:27.665Z"
   },
   {
    "duration": 24140,
    "start_time": "2022-07-18T09:24:27.901Z"
   },
   {
    "duration": 1881,
    "start_time": "2022-07-18T09:24:52.042Z"
   },
   {
    "duration": 99,
    "start_time": "2022-07-18T09:24:53.925Z"
   },
   {
    "duration": 38,
    "start_time": "2022-07-18T09:24:54.026Z"
   },
   {
    "duration": 24634,
    "start_time": "2022-07-18T09:24:54.065Z"
   },
   {
    "duration": 207,
    "start_time": "2022-07-18T09:36:24.477Z"
   },
   {
    "duration": 230,
    "start_time": "2022-07-18T09:44:42.777Z"
   },
   {
    "duration": 1564,
    "start_time": "2022-07-18T09:47:17.062Z"
   },
   {
    "duration": 289,
    "start_time": "2022-07-18T09:51:49.892Z"
   },
   {
    "duration": 24359,
    "start_time": "2022-07-18T09:57:47.242Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-18T09:59:34.130Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-18T10:05:54.621Z"
   },
   {
    "duration": 52,
    "start_time": "2022-07-18T10:06:03.435Z"
   },
   {
    "duration": 10,
    "start_time": "2022-07-18T10:06:36.450Z"
   },
   {
    "duration": 9,
    "start_time": "2022-07-18T10:06:45.791Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-18T10:08:02.563Z"
   },
   {
    "duration": 1122,
    "start_time": "2022-07-18T10:13:02.211Z"
   },
   {
    "duration": 50,
    "start_time": "2022-07-18T10:13:03.335Z"
   },
   {
    "duration": 23,
    "start_time": "2022-07-18T10:13:03.387Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-18T10:13:03.411Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-18T10:13:03.430Z"
   },
   {
    "duration": 15,
    "start_time": "2022-07-18T10:13:03.438Z"
   },
   {
    "duration": 7,
    "start_time": "2022-07-18T10:13:03.454Z"
   },
   {
    "duration": 29,
    "start_time": "2022-07-18T10:13:03.462Z"
   },
   {
    "duration": 23,
    "start_time": "2022-07-18T10:13:03.493Z"
   },
   {
    "duration": 8,
    "start_time": "2022-07-18T10:13:03.524Z"
   },
   {
    "duration": 35,
    "start_time": "2022-07-18T10:13:03.537Z"
   },
   {
    "duration": 5,
    "start_time": "2022-07-18T10:13:03.573Z"
   },
   {
    "duration": 12,
    "start_time": "2022-07-18T10:13:03.579Z"
   },
   {
    "duration": 240,
    "start_time": "2022-07-18T10:13:03.594Z"
   },
   {
    "duration": 24288,
    "start_time": "2022-07-18T10:13:03.836Z"
   },
   {
    "duration": 1899,
    "start_time": "2022-07-18T10:13:28.126Z"
   },
   {
    "duration": 101,
    "start_time": "2022-07-18T10:13:30.030Z"
   },
   {
    "duration": 46,
    "start_time": "2022-07-18T10:13:30.133Z"
   },
   {
    "duration": 23744,
    "start_time": "2022-07-18T10:13:30.181Z"
   },
   {
    "duration": 237,
    "start_time": "2022-07-18T10:13:53.927Z"
   },
   {
    "duration": 1757,
    "start_time": "2022-07-18T10:13:54.166Z"
   },
   {
    "duration": 379,
    "start_time": "2022-07-18T10:13:55.925Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-18T10:13:56.305Z"
   },
   {
    "duration": 54,
    "start_time": "2022-07-18T10:13:56.323Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-18T10:13:56.380Z"
   },
   {
    "duration": 29,
    "start_time": "2022-07-18T10:13:56.394Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-18T10:13:56.425Z"
   },
   {
    "duration": 1245,
    "start_time": "2022-07-19T00:52:23.998Z"
   },
   {
    "duration": 104,
    "start_time": "2022-07-19T00:52:25.245Z"
   },
   {
    "duration": 29,
    "start_time": "2022-07-19T00:52:25.355Z"
   },
   {
    "duration": 22,
    "start_time": "2022-07-19T00:52:25.386Z"
   },
   {
    "duration": 17,
    "start_time": "2022-07-19T00:52:25.410Z"
   },
   {
    "duration": 18,
    "start_time": "2022-07-19T00:52:25.429Z"
   },
   {
    "duration": 6,
    "start_time": "2022-07-19T00:52:25.449Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-19T00:52:25.457Z"
   },
   {
    "duration": 43,
    "start_time": "2022-07-19T00:52:25.480Z"
   },
   {
    "duration": 15,
    "start_time": "2022-07-19T00:52:25.525Z"
   },
   {
    "duration": 19,
    "start_time": "2022-07-19T00:52:25.542Z"
   },
   {
    "duration": 4,
    "start_time": "2022-07-19T00:52:25.563Z"
   },
   {
    "duration": 16,
    "start_time": "2022-07-19T00:52:25.569Z"
   },
   {
    "duration": 239,
    "start_time": "2022-07-19T00:52:25.587Z"
   },
   {
    "duration": 24948,
    "start_time": "2022-07-19T00:52:25.830Z"
   },
   {
    "duration": 1937,
    "start_time": "2022-07-19T00:52:50.780Z"
   },
   {
    "duration": 92,
    "start_time": "2022-07-19T00:52:52.721Z"
   },
   {
    "duration": 84,
    "start_time": "2022-07-19T00:52:52.814Z"
   },
   {
    "duration": 27142,
    "start_time": "2022-07-19T00:52:52.900Z"
   },
   {
    "duration": 288,
    "start_time": "2022-07-19T00:53:20.044Z"
   },
   {
    "duration": 1406,
    "start_time": "2022-07-19T00:53:20.334Z"
   },
   {
    "duration": 437,
    "start_time": "2022-07-19T00:53:21.810Z"
   },
   {
    "duration": 11,
    "start_time": "2022-07-19T00:53:22.250Z"
   },
   {
    "duration": 67,
    "start_time": "2022-07-19T00:53:22.263Z"
   },
   {
    "duration": 9,
    "start_time": "2022-07-19T00:53:22.332Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-19T00:53:22.343Z"
   },
   {
    "duration": 13,
    "start_time": "2022-07-19T00:53:22.359Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199.801px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
